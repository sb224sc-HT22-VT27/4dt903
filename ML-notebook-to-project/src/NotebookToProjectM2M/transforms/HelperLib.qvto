import CodeClassificationLib;
import transformationutils.FilePathTransformer;

library HelperLib;

modeltype NotebookMM uses "http://www.g7.org/notebookMM";
modeltype ProjectStuctureMM uses "http://www.g7.org/projectStructureMM";

/**
 * Returns a Sequence of Strings representing the code of the given notebook.
 * File paths are updated to match the new project structure where code is in src/
 * and data files are in data/, models/, etc.
 * @return Sequence(String)
 */
helper generateMainPyContent(notebook : NotebookMM::NotebookModel) : Sequence(String) {
    var contentLines : Sequence(String) := Sequence{};

    // Iterate through all cells in order
    notebook.cells->forEach(cell) {
        if cell.oclIsTypeOf(NotebookMM::MarkdownCell) then {
            // Convert markdown cell to Python docstring
            var mdCell := cell.oclAsType(NotebookMM::MarkdownCell);
            if mdCell.content <> null and mdCell.content <> '' then {
                contentLines += '\n"""\n' + mdCell.content + '\n"""\n\n';
            } endif;
        } else if cell.oclIsTypeOf(NotebookMM::CodeCell) then {
            // Transform file paths in code to match new project structure
            var codeCell := cell.oclAsType(NotebookMM::CodeCell);
            if codeCell.source <> null and codeCell.source <> '' then {
                var transformedSource := transformFilePathsJava(codeCell.source);
                contentLines += '\n' + transformedSource + CodeClassificationLib::getClassificationCommentQVTo(codeCell.source) + '\n\n';
            } endif;
        } endif endif;
    };
	return contentLines;
}

/**
 * Transforms file paths in Python code using Java helper.
 * Uses FilePathTransformer to update paths for the new project structure.
 * @param source The original source code
 * @return The source code with updated file paths
 */
helper transformFilePathsJava(source : String) : String {
    return FilePathTransformer::transformFilePaths(source);
}

/**
 * Returns the main.py entry point content that imports from preprocess, train, and predict modules.
 * @return Sequence(String)
 */
helper generateMainPyEntryContent(notebook : NotebookMM::NotebookModel) : Sequence(String) {
    var contentLines : Sequence(String) := Sequence{};
    
    // Add docstring from first markdown cell if available
    notebook.cells->forEach(cell) {
        if cell.oclIsTypeOf(NotebookMM::MarkdownCell) then {
            var mdCell := cell.oclAsType(NotebookMM::MarkdownCell);
            if mdCell.content <> null and mdCell.content <> '' then {
                contentLines += '"""\n' + mdCell.content + '\n"""\n';
                break;
            } endif;
        } endif;
    };

    // Add imports from the stage modules
    contentLines += '# Import stage modules';
    contentLines += 'from preprocess import run_preprocessing';
    contentLines += 'from train import run_training';
    contentLines += 'from predict import run_prediction';
    contentLines += '';
    contentLines += 'def main():';
    contentLines += '    """\n\tMain entry point that orchestrates the ML pipeline. \n\tExecutes preprocessing, training, and prediction stages in sequence.\n\t"""';
    contentLines += '    print("Starting ML Pipeline...")';
    contentLines += '    ';
    contentLines += '    print("\\n=== Preprocessing Stage ===")';
    contentLines += '    run_preprocessing()';
    contentLines += '    ';
    contentLines += '    print("\\n=== Training Stage ===")';
    contentLines += '    run_training()';
    contentLines += '    ';
    contentLines += '    print("\\n=== Prediction Stage ===")';
    contentLines += '    run_prediction()';
    contentLines += '    ';
    contentLines += '    print("\\nML Pipeline completed!")';
    contentLines += '';
    contentLines += '';
    contentLines += 'if __name__ == "__main__":';
    contentLines += '    main()';
    contentLines += '';

    return contentLines;
}

/**
 * Collects imports from code cells that match the specified stage.
 * @param notebook The notebook model
 * @param stage The stage name: "preprocess", "train", or "predict"
 * @return Sequence of import statements
 */
helper collectImportsForStage(notebook : NotebookMM::NotebookModel, stage : String) : Sequence(String) {
    var imports : Sequence(String) := Sequence{};

    notebook.cells->forEach(cell) {
        if cell.oclIsTypeOf(NotebookMM::CodeCell) then {
            var codeCell := cell.oclAsType(NotebookMM::CodeCell);
            if codeCell.source <> null and codeCell.source <> '' then {
                var isMatch : Boolean := false;
                if stage = 'preprocess' then {
                    isMatch := codeCell.isDataPreprocessing();
                } elif stage = 'train' then {
                    isMatch := codeCell.isTrainingCode();
                } elif stage = 'predict' then {
                    isMatch := codeCell.isPredictionCode();
                } endif;

                if isMatch then {
                    codeCell.extractImports()->forEach(imp) {
                        imports += imp;
                    };
                } endif;
            } endif;
        } endif;
    };

    return imports;
}

/**
 * Generates indented code blocks for cells matching the specified stage.
 * @param notebook The notebook model
 * @param stage The stage name: "preprocess", "train", or "predict"
 * @return Sequence of indented code lines with comments
 */
helper generateCodeBlocksForStage(notebook : NotebookMM::NotebookModel, stage : String) : Sequence(String) {
    var contentLines : Sequence(String) := Sequence{};
    var hasCode : Boolean := false;

    notebook.cells->forEach(cell) {
        if cell.oclIsTypeOf(NotebookMM::CodeCell) then {
            var codeCell := cell.oclAsType(NotebookMM::CodeCell);
            if codeCell.source <> null and codeCell.source <> '' then {
                var isMatch : Boolean := false;
                if stage = 'preprocess' then {
                    isMatch := codeCell.isDataPreprocessing();
                } elif stage = 'train' then {
                    isMatch := codeCell.isTrainingCode();
                } elif stage = 'predict' then {
                    isMatch := codeCell.isPredictionCode();
                } endif;

                if isMatch then {
                    hasCode := true;
                    contentLines += '';
                    contentLines += codeCell.extractConstants()->asSequence(); // TESTING 
                    // Capitalize first letter of stage name
                    var stageLabel : String := if stage = 'preprocess' then 'Preprocess' elif stage = 'train' then 'Train' else 'Predict' endif;
                    contentLines += '# ' + stageLabel + ' code block';
                    codeCell.getSourceLines()->forEach(line) {contentLines += '\t' + line;};
                } endif;
            } endif;
        } endif;
    };

    if not hasCode then {
        contentLines += '\tpass  # No ' + stage + ' code blocks found';
    } endif;

    return contentLines;
}

/**
 * Returns the content for preprocess.py containing preprocessing code blocks.
 * @return Sequence(String)
 */
helper generatePreprocessPyContent(notebook : NotebookMM::NotebookModel) : Sequence(String) {
    var contentLines : Sequence(String) := Sequence{};

    contentLines += '"""\nPreprocessing module - Contains data loading and preprocessing logic. \n"""';
    contentLines += '';

    // Collect imports for preprocessing stage
    collectImportsForStage(notebook, 'preprocess')->forEach(imp) {
        contentLines += imp;
    };

    contentLines += '';
    contentLines += '';
    contentLines += 'def run_preprocessing():';
    contentLines += '\t"""\n\tExecute all preprocessing steps. \n\t"""';

    // Generate code blocks for preprocessing stage
    contentLines := contentLines->union(generateCodeBlocksForStage(notebook, 'preprocess'));

    contentLines += '';

    return contentLines;
}

/**
 * Returns the content for train.py containing training code blocks.
 * @return Sequence(String)
 */
helper generateTrainPyContent(notebook : NotebookMM::NotebookModel) : Sequence(String) {
    var contentLines : Sequence(String) := Sequence{};

    contentLines += '"""\nTraining module - Contains model training logic.\n"""';
    contentLines += '';

    // Collect imports for training stage
    collectImportsForStage(notebook, 'train')->forEach(imp) {
        contentLines += imp;
    };


    contentLines += '';
    contentLines += 'def run_training():';
    contentLines += '\t"""\n\tExecute all training steps.\n\t"""';

    // Generate code blocks for training stage
    contentLines := contentLines->union(generateCodeBlocksForStage(notebook, 'train'));

    contentLines += '';

    return contentLines;
}

/**
 * Returns the content for predict.py containing prediction code blocks.
 * @return Sequence(String)
 */
helper generatePredictPyContent(notebook : NotebookMM::NotebookModel) : Sequence(String) {
    var contentLines : Sequence(String) := Sequence{};

    contentLines += '""" \nPrediction module - Contains model prediction/inference logic. \n"""';
    contentLines += '';

    // Collect imports for prediction stage
    collectImportsForStage(notebook, 'predict')->forEach(imp) {
        contentLines += imp;
    };


    contentLines += '';
    contentLines += '';
    contentLines += 'def run_prediction():';
    contentLines += '\t"""\n\tExecute all prediction steps.\n\t"""';

    // Generate code blocks for prediction stage
    contentLines := contentLines->union(generateCodeBlocksForStage(notebook, 'predict'));

    contentLines += '';

    return contentLines;
}

/**
 * Returns an OrderedSet of String names of imported packages in python for pip to install.
 * Always includes flask for the prediction service.
 * @return OrderedSet(String)
 */
helper extractPackageNames(notebook : NotebookMM::NotebookModel) : OrderedSet(String) {
	var imports : OrderedSet(String) := notebook.getAllImports();
	var packages : OrderedSet(String) := 
		imports 
		->collect(importStmt | mapImportToPackage(importStmt)) 
		->select(pkg | pkg <> '') 
		->asOrderedSet(); 
	
	// Always include flask for the prediction service
	packages += 'flask';
	
	return packages;
}

/**
 * Returns the assumed String name of a package.
 * @return String
 */
helper mapImportToPackage(importStmt : String) : String {
	if importStmt.indexOf('sklearn') > 0 then
	return 'scikit-learn'
	elif importStmt.indexOf('cv2') > 0 then
	return 'opencv-python'
	elif importStmt.indexOf('PIL') > 0 then
	return 'Pillow'
	elif importStmt.indexOf('pandas') > 0 then
	return 'pandas'
	elif importStmt.indexOf('numpy') > 0 then
	return 'numpy'
	elif importStmt.indexOf('matplotlib') > 0 then
	return 'matplotlib'
	elif importStmt.indexOf('scipy') > 0 then
	return 'scipy'
	elif importStmt.indexOf('seaborn') > 0 then
	return 'seaborn'
	elif importStmt.indexOf('joblib') > 0 then
	return 'joblib'
	elif importStmt.indexOf('tensorflow') > 0 then
	return 'tensorflow'
	elif importStmt.indexOf('torch') > 0 then
	return 'torch'
	elif importStmt.indexOf('keras') > 0 then
	return 'keras'
	elif importStmt.indexOf('flask') > 0 then
	return 'flask'
	elif importStmt.indexOf('django') > 0 then
	return 'django'
	elif importStmt.indexOf('requests') > 0 then
	return 'requests'
	elif importStmt.indexOf('sqlalchemy') > 0 then
	return 'sqlalchemy'
	elif importStmt.indexOf('pytest') > 0 then
	return 'pytest'
	elif importStmt.indexOf('yaml') > 0 then
	return 'PyYAML'
	elif importStmt.indexOf('bs4') > 0 then
	return 'beautifulsoup4'
	elif importStmt.indexOf('dateutil') > 0 then
	return 'python-dateutil'
	else
	return ''
	endif
}

/**
 * Returns a Sequence of Strings representing the content of a Dockerfile.
 * The Dockerfile sets up a Python venv, installs requirements, and runs the prediction server.
 * Uses the Python version from notebook metadata if available, defaults to 3.13-slim.
 * @return Sequence(String)
 */
helper generateDockerfileContent(notebook : NotebookMM::NotebookModel) : Sequence(String) {
	var dockerImage : String := mapPythonVersionToDockerImage(notebook);
	return Sequence{
		'FROM ' + dockerImage,
		'',
		'WORKDIR /app',
		'\n# Copy requirements first (for better caching)',
		'COPY requirements.txt .',
		'',
		'\n# Set up virtual environment and install dependencies',
		'RUN python -m venv /opt/venv',
		'ENV PATH="/opt/venv/bin:$PATH"',
		'\n',
		'# Install dependencies',
		'RUN pip install --upgrade pip && \\ 
		pip install -r requirements.txt',
		'\n',
		'\n# Copy project files',
		'COPY src/ ./src/',
		'COPY data/ ./data/',
		'COPY models/ ./models/',
		'COPY outputs/ ./outputs/',
		'\n',
		'# Expose port for prediction service',
		'EXPOSE 8080',
		'\n',
		'\n# Run the prediction server',
		'CMD ["python", "src/server.py"]'
	};
}

/**
 * Returns a Sequence of Strings representing the content of server.py.
 * Creates a Flask-based prediction service accessible at localhost:8080/predict.
 * @return Sequence(String)
 */
helper generateServerPyContent() : Sequence(String) {
	return Sequence{
		'"""',
		'Prediction Service - Flask-based REST API for model predictions.',
		'Accessible at localhost:8080/predict',
		'"""',
		'',
		'from flask import Flask, request, jsonify',
		'import joblib',
		'import numpy as np',
		'import os',
		'',
		'app = Flask(__name__)',
		'',
		'# Load model and scaler at startup',
		'MODEL_PATH = os.path.join(os.path.dirname(__file__), "..", "models")',
		'model = None',
		'scaler = None',
		'feature_names = None',
		'',
		'def load_model():',
		'    """Load the trained model and associated artifacts."""',
		'    global model, scaler, feature_names',
		'    try:',
		'        # Try to load common model artifacts',
		'        model_files = [f for f in os.listdir(MODEL_PATH) if f.endswith(".pkl") or f.endswith(".keras") or f.endswith(".h5")]',
		'        for f in model_files:',
		'            filepath = os.path.join(MODEL_PATH, f)',
		'            if f.endswith(".keras") or f.endswith(".h5"):', 
		'                # Load Keras/TensorFlow models',
		'                try:',
		'                    from tensorflow import keras',
		'                    model = keras.models.load_model(filepath)',
		'                except ImportError:',
		'                    print("TensorFlow not available for loading .keras/.h5 model")',
		'            elif "model" in f.lower() and "scaler" not in f.lower():',
		'                model = joblib.load(filepath)',
		'            elif "scaler" in f.lower():',
		'                scaler = joblib.load(filepath)',
		'            elif "feature" in f.lower():',
		'                feature_names = joblib.load(filepath)',
		'        print("Model loaded successfully")',
		'    except Exception as e:',
		'        print(f"Error loading model: {e}")',
		'',
		'@app.route("/predict", methods=["POST"])',
		'def predict():',
		'    """',
		'    Prediction endpoint.',
		'    Expects JSON input with features for prediction.',
		'    Returns JSON with prediction results.',
		'    """',
		'    try:',
		'        if model is None:',
		'            return jsonify({"error": "Model not loaded"}), 500',
		'        ',
		'        data = request.get_json()',
		'        if data is None:',
		'            return jsonify({"error": "No JSON data provided"}), 400',
		'        ',
		'        # Extract features from request',
		'        features = data.get("features")',
		'        if features is None:',
		'            return jsonify({"error": "No features provided"}), 400',
		'        ',
		'        # Convert to numpy array',
		'        features_array = np.array(features).reshape(1, -1)',
		'        ',
		'        # Apply scaler if available',
		'        if scaler is not None:',
		'            features_array = scaler.transform(features_array)',
		'        ',
		'        # Make prediction',
		'        prediction = model.predict(features_array)',
		'        ',
		'        # Try to get probability if available',
		'        try:',
		'            probability = model.predict_proba(features_array).tolist()',
		'        except AttributeError:',
		'            probability = None',
		'        ',
		'        response = {',
		'            "prediction": prediction.tolist() if hasattr(prediction, "tolist") else prediction,',
		'            "probability": probability',
		'        }',
		'        ',
		'        return jsonify(response)',
		'        ',
		'    except Exception as e:',
		'        return jsonify({"error": str(e)}), 500',
		'',
		'@app.route("/health", methods=["GET"])',
		'def health():',
		'    """Health check endpoint."""',
		'    return jsonify({"status": "healthy", "model_loaded": model is not None})',
		'',
		'if __name__ == "__main__":',
		'    load_model()',
		'    app.run(host="0.0.0.0", port=8080)'
	};
}

helper generateDockerIgnoreContent() : Sequence(String) {
	return Sequence{
		'__pycache__',
		'*.pyc',
		'.git',
		'.env'
	}
}

/**
 * Maps a Python version from notebook metadata to a valid Docker image tag.
 * Extracts major.minor version and maps to python:X.Y-slim format.
 * Defaults to python:3.13-slim if version cannot be mapped.
 * @return String - Docker image name with tag (e.g., 'python:3.11-slim')
 */
helper mapPythonVersionToDockerImage(notebook : NotebookMM::NotebookModel) : String {
	var defaultImage : String := 'python:3.13-slim';

	// Check if metadata and pythonVersion exist
	if notebook.metadata = null then
		return defaultImage
	endif;

	var version : String := notebook.metadata.pythonVersion;
	if version = null or version = '' then
		return defaultImage
	endif;

	// Extract major.minor version (e.g., "3.11.5" -> "3.11")
	var majorMinor : String := extractMajorMinorVersion(version);
	if majorMinor = '' then
		return defaultImage
	endif;

	// Map to supported Docker image versions
	// Official Python Docker images exist for: 3.8, 3.9, 3.10, 3.11, 3.12, 3.13
	if majorMinor = '3.8' or majorMinor = '3.9' or majorMinor = '3.10' or 
	   majorMinor = '3.11' or majorMinor = '3.12' or majorMinor = '3.13' then
		return 'python:' + majorMinor + '-slim'
	else
		return defaultImage
	endif;
}

/**
 * Extracts major.minor version from a full version string.
 * E.g., "3.11.5" -> "3.11", "3.13.7" -> "3.13"
 * @return String - major.minor version or empty string if invalid
 */
helper extractMajorMinorVersion(version : String) : String {
	// Find first dot
	var firstDot : Integer := version.indexOf('.');
	if firstDot <= 0 then
		return ''
	endif;

	// Find second dot (if exists)
	var afterFirstDot : String := version.substring(firstDot + 1, version.size());
	var secondDot : Integer := afterFirstDot.indexOf('.');

	if secondDot > 0 then
		// Version has patch number, extract major.minor
		// firstDot + secondDot gives us the position up to minor version
		return version.substring(1, firstDot + secondDot)
	else
		// Version is already major.minor
		return version
	endif;
}