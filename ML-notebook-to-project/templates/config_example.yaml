# Example Configuration File for Generated ML Projects
# This file demonstrates the structure of configs/config.yaml

# Project Information
project:
  name: "my_ml_project"
  version: "0.1.0"
  description: "Machine Learning project description"
  author: "Author Name"

# Directory Paths
paths:
  project_root: "."
  data_dir: "data"
  raw_data: "data/raw"
  processed_data: "data/processed"
  models_dir: "models"
  outputs_dir: "outputs"
  logs_dir: "outputs/logs"

# Data Configuration
data:
  # Data splits
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15
  
  # Random seed for reproducibility
  random_seed: 42
  
  # Data loading
  file_format: "csv"  # csv, parquet, json
  target_column: "target"
  
  # Preprocessing options
  handle_missing: "drop"  # drop, fill, interpolate
  normalize: true
  encoding_strategy: "onehot"  # onehot, label, ordinal

# Feature Engineering
features:
  # Feature selection
  feature_selection: false
  num_features: null
  
  # Feature scaling
  scaler_type: "standard"  # standard, minmax, robust
  
  # Feature engineering techniques
  polynomial_features: false
  polynomial_degree: 2

# Model Configuration
model:
  # Model type
  type: "classification"  # classification, regression, clustering
  algorithm: "random_forest"  # random_forest, neural_network, xgboost, etc.
  
  # Model hyperparameters (example for Random Forest)
  hyperparameters:
    n_estimators: 100
    max_depth: 10
    min_samples_split: 2
    min_samples_leaf: 1
    random_state: 42
  
  # For neural networks
  # architecture:
  #   layers: [64, 32, 16]
  #   activation: "relu"
  #   dropout: 0.2
  #   output_activation: "softmax"

# Training Configuration
training:
  # Basic training parameters
  batch_size: 32
  epochs: 100
  learning_rate: 0.001
  
  # Optimizer (for neural networks)
  optimizer: "adam"
  optimizer_params:
    beta_1: 0.9
    beta_2: 0.999
    epsilon: 1e-07
  
  # Loss function
  loss_function: "categorical_crossentropy"  # or "mse", "binary_crossentropy", etc.
  
  # Metrics to track
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 10
    monitor: "val_loss"
    min_delta: 0.001
  
  # Model checkpointing
  checkpointing:
    enabled: true
    save_best_only: true
    monitor: "val_accuracy"
    save_frequency: "epoch"
  
  # Learning rate scheduling
  lr_scheduler:
    enabled: false
    type: "reduce_on_plateau"  # reduce_on_plateau, step_decay, exponential
    factor: 0.5
    patience: 5

# Evaluation Configuration
evaluation:
  # Metrics for final evaluation
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"
    - "roc_auc"
    - "confusion_matrix"
  
  # Cross-validation
  cross_validation:
    enabled: false
    n_folds: 5
    stratified: true
  
  # Threshold tuning (for classification)
  threshold_tuning:
    enabled: false
    metric: "f1_score"

# Inference Configuration
inference:
  # Batch prediction settings
  batch_size: 64
  
  # Model loading
  model_path: "models/production/model.pkl"
  
  # Output format
  output_format: "csv"  # csv, json, parquet
  include_probabilities: true

# Logging Configuration
logging:
  # Logging level
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  
  # Log format
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
  # Log destinations
  console: true
  file: true
  
  # Experiment tracking
  experiment_tracking:
    enabled: false
    backend: "mlflow"  # mlflow, wandb, tensorboard
    experiment_name: "my_experiment"
    run_name: "run_001"

# Deployment Configuration
deployment:
  # API settings
  api:
    host: "0.0.0.0"
    port: 8000
    reload: false
  
  # Model serving
  model_serving:
    framework: "fastapi"  # fastapi, flask, torchserve
    batch_inference: false
    max_batch_size: 32
    timeout: 30

# Resource Configuration
resources:
  # CPU/GPU settings
  device: "cpu"  # cpu, cuda, mps
  num_workers: 4
  
  # Memory management
  memory_limit: null
  cache_data: true

# Experiment Configuration
experiment:
  # Experiment tracking
  name: "baseline_experiment"
  tags:
    - "baseline"
    - "initial_run"
  
  # Reproducibility
  deterministic: true
  seed: 42
  
  # Save artifacts
  save_predictions: true
  save_model: true
  save_figures: true
  save_metrics: true
